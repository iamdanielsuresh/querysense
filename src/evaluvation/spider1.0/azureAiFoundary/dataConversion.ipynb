{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spider Dataset to Azure AI Foundry JSONL Conversion\n",
                "\n",
                "This notebook converts the Spider text-to-SQL dataset into the JSONL format required for fine-tuning GPT-4o mini on Azure AI Foundry.\n",
                "\n",
                "**Goal Format:**\n",
                "```json\n",
                "{\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "We define the paths to the Spider dataset files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "11dd1e2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths (assuming notebook is in spider/azureAiFoundary/)\n",
                "base_path = \"../\"\n",
                "tables_path = os.path.join(base_path, \"tables.json\")\n",
                "train_path = os.path.join(base_path, \"train_spider.json\")\n",
                "dev_path = os.path.join(base_path, \"dev.json\")\n",
                "output_path = \"spider_finetuning.jsonl\"\n",
                "val_output_path = \"spider_validation.jsonl\"\n",
                "\n",
                "print(f\"Tables path: {tables_path}\")\n",
                "print(f\"Train path: {train_path}\")\n",
                "print(f\"Dev path: {dev_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d126b6f",
            "metadata": {},
            "source": [
                "## 2. Process Schemas\n",
                "We need to create a string representation of the database schema for each `db_id` to include in the system prompt. This helps the model understand the table structures."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca24421e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_schemas(tables_path):\n",
                "    with open(tables_path, 'r') as f:\n",
                "        tables_data = json.load(f)\n",
                "    \n",
                "    schemas = {}\n",
                "    for db in tables_data:\n",
                "        db_id = db['db_id']\n",
                "        table_names = db['table_names_original']\n",
                "        column_names = db['column_names_original']\n",
                "        \n",
                "        # Organize columns by table index\n",
                "        table_cols = {i: [] for i in range(len(table_names))}\n",
                "        for col_idx, (table_idx, col_name) in enumerate(column_names):\n",
                "            if table_idx >= 0: # -1 is usually for \"*\"\n",
                "                table_cols[table_idx].append(col_name)\n",
                "        \n",
                "        # Format schema string\n",
                "        schema_parts = []\n",
                "        for i, table_name in enumerate(table_names):\n",
                "            cols = \", \".join(table_cols[i])\n",
                "            schema_parts.append(f\"Table: {table_name}, columns: [{cols}]\")\n",
                "        \n",
                "        schemas[db_id] = \"\\n\".join(schema_parts)\n",
                "    \n",
                "    return schemas\n",
                "\n",
                "schemas = load_schemas(tables_path)\n",
                "print(f\"Loaded schemas for {len(schemas)} databases.\")\n",
                "# Example schema\n",
                "example_db = list(schemas.keys())[0]\n",
                "print(f\"\\nExample Schema ({example_db}):\\n{schemas[example_db]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3a4d158e",
            "metadata": {},
            "source": [
                "## 3. Convert to JSONL\n",
                "Iterate through the training examples and format them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2fb12c7e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def convert_to_jsonl(input_path, schemas, output_path):\n",
                "    with open(input_path, 'r') as f:\n",
                "        data = json.load(f)\n",
                "    \n",
                "    with open(output_path, 'w') as f_out:\n",
                "        for item in data:\n",
                "            db_id = item['db_id']\n",
                "            question = item['question']\n",
                "            query = item['query']\n",
                "            \n",
                "            if db_id not in schemas:\n",
                "                print(f\"Warning: Schema not found for {db_id}\")\n",
                "                continue\n",
                "            \n",
                "            schema_context = schemas[db_id]\n",
                "            \n",
                "            # Construct the chat message\n",
                "            system_message = f\"You are a helpful assistant that translates natural language questions into SQL queries.\\nThe database schema is as follows:\\n{schema_context}\"\n",
                "            \n",
                "            jsonl_entry = {\n",
                "                \"messages\": [\n",
                "                    {\"role\": \"system\", \"content\": system_message},\n",
                "                    {\"role\": \"user\", \"content\": question},\n",
                "                    {\"role\": \"assistant\", \"content\": query}\n",
                "                ]\n",
                "            }\n",
                "            \n",
                "            f_out.write(json.dumps(jsonl_entry) + \"\\n\")\n",
                "            \n",
                "    print(f\"Converted {len(data)} examples from {input_path} to {output_path}\")\n",
                "\n",
                "# Convert Training Data\n",
                "convert_to_jsonl(train_path, schemas, output_path)\n",
                "\n",
                "# Convert Validation Data\n",
                "if os.path.exists(dev_path):\n",
                "    convert_to_jsonl(dev_path, schemas, val_output_path)\n",
                "else:\n",
                "    print(f\"Warning: {dev_path} not found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "738809bc",
            "metadata": {},
            "source": [
                "## 4. Verify Output\n",
                "Check the first few lines of the generated files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28408e1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"First 2 lines of training output:\")\n",
                "with open(output_path, 'r') as f:\n",
                "    for i in range(2):\n",
                "        print(f.readline())\n",
                "\n",
                "print(\"\\nFirst 2 lines of validation output:\")\n",
                "if os.path.exists(val_output_path):\n",
                "    with open(val_output_path, 'r') as f:\n",
                "        for i in range(2):\n",
                "            print(f.readline())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
